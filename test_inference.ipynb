{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from models import SwinTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e8b4d",
   "metadata": {},
   "source": [
    "### Please modify the path of pretrained weight and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weight_path = 'DWCC.pt'\n",
    "test_path = '/covid/data/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a5b20",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8964a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SwinTransformer(img_size=224,\n",
    "                        patch_size=4,\n",
    "                        in_chans=3,\n",
    "                        num_classes=1,\n",
    "                        embed_dim=96,\n",
    "                        depths=[2, 2, 6, 2],\n",
    "                        num_heads=[3, 6, 12, 24],\n",
    "                        window_size=7,\n",
    "                        mlp_ratio=4.0,\n",
    "                        qkv_bias=True,\n",
    "                        qk_scale=None,\n",
    "                        drop_rate=0.0,\n",
    "                        drop_path_rate=0.2,\n",
    "                        ape=False,\n",
    "                        patch_norm=True,\n",
    "                        use_checkpoint=False,\n",
    "                        device=device)\n",
    "\n",
    "model.load_state_dict(torch.load(pretrained_weight_path), strict=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dadc92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0.39221061670618984\n",
    "s = 0.11469786773730418\n",
    "t = transforms.Compose([transforms.ToPILImage(),\n",
    "                        transforms.Resize((224,224)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((m, m, m), (s, s, s))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d290cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(path, st=3, ed=7, model=model, t=t):\n",
    "    \n",
    "    model.eval()\n",
    "    img_list = os.listdir(path)\n",
    "    sort_index = sorted(range(len(img_list)), key=lambda k: int(img_list[k].split('.')[0]))\n",
    "    ct_len = len(sort_index)\n",
    "    start_idx = int(round(ct_len / 10 * st, 0))\n",
    "    end_idx = int(round(ct_len / 10 * ed, 0)) + 1\n",
    "    \n",
    "    pop = []\n",
    "    for i in range(start_idx, end_idx):\n",
    "        img_path = os.path.join(path, img_list[sort_index[i]])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = t(img).to(device).unsqueeze(0)\n",
    "        output = model(img)\n",
    "        pop.append(output.item())\n",
    "\n",
    "    p_value = wilcoxon_rank_test(pop)\n",
    "    if p_value < 0.05:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilcoxon_rank_test(pop):\n",
    "    pop = np.array(pop)\n",
    "    postive_pop = pop[(pop >= 1 - np.sqrt(0.2) * 2) & (pop <= 1 + np.sqrt(0.2) * 2)]\n",
    "    negative_pop = pop[(pop >= -1 - np.sqrt(0.2) * 2) & (pop <= -1 + np.sqrt(0.2) * 2)]\n",
    "    total_pop = len(postive_pop) + len(negative_pop)\n",
    "    if total_pop == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        w, p = wilcoxon(np.concatenate((postive_pop, negative_pop)), alternative='greater')\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e7f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid = []\n",
    "non_covid = []\n",
    "\n",
    "test_folder = os.listdir(test_path)\n",
    "for folder in tqdm(test_folder):\n",
    "    path = os.path.join(test_path, folder)\n",
    "    pred = inference(path)\n",
    "    if pred == 1:\n",
    "        covid.append(folder)\n",
    "    else:\n",
    "        non_covid.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72839a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/covid.csv', 'w', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(covid)\n",
    "    \n",
    "with open('result/non-covid.csv', 'w', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(non_covid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin",
   "language": "python",
   "name": "swin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
